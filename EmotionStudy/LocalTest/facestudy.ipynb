{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape after cnn1  (?, 48, 48, 16)\n",
      "shape after cnn2 : (?, 24, 24, 32)\n",
      "## FLAGS.stride1  1\n",
      "shape after cnn3 : (?, 12, 12, 64)\n",
      "shape after cnn4 : (?, 6, 6, 128)\n",
      "shape after fc1 : (?, 512)\n",
      "shape after fc2 : (?, 256)\n",
      "shape after dropout : (?, 256)\n",
      "shape after final layer : (?, 5)\n",
      "WARNING:tensorflow:From <ipython-input-1-253fa2fb6763>:264: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "## time: 0:00:03.784312  steps: 0\n",
      "Prediction loss: 174.76898  accuracy: 0.02\n",
      "Validation loss: 237.10675  accuracy: 0.04\n",
      "## time: 0:00:29.247095  steps: 10\n",
      "Prediction loss: 36.79177  accuracy: 0.02\n",
      "Validation loss: 85.64366  accuracy: 0.01\n",
      "## time: 0:00:52.864708  steps: 20\n",
      "Prediction loss: 37.070206  accuracy: 0.36\n",
      "Validation loss: 59.87043  accuracy: 0.37\n",
      "## time: 0:01:13.508922  steps: 30\n",
      "Prediction loss: 36.315342  accuracy: 0.01\n",
      "Validation loss: 69.518845  accuracy: 0.02\n",
      "## time: 0:01:35.253445  steps: 40\n",
      "Prediction loss: 125.08813  accuracy: 0.05\n",
      "Validation loss: 105.46512  accuracy: 0.05\n",
      "## time: 0:01:55.274507  steps: 50\n",
      "Prediction loss: 114.82879  accuracy: 0.06\n",
      "Validation loss: 89.39215  accuracy: 0.1\n",
      "## time: 0:02:15.847956  steps: 60\n",
      "Prediction loss: 188.62718  accuracy: 0.08\n",
      "Validation loss: 250.02922  accuracy: 0.08\n",
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Enqueue operation was cancelled\n",
      "\t [[Node: input_producer/input_producer/input_producer_EnqueueMany = QueueEnqueueManyV2[Tcomponents=[DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](input_producer/input_producer, input_producer/input_producer/RandomShuffle)]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-253fa2fb6763>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'finish'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 333\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-253fa2fb6763>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(argv)\u001b[0m\n\u001b[0;32m    300\u001b[0m             \u001b[0mimages_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel_batch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;31m#sess.run(train_step,feed_dict={images:images_,labels:labels_,keep_prob:0.8})\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m             \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mimages_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0.7\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import  tensorflow  as tf\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "TRAINING_FILE = '/CroppedData/training_file.txt'\n",
    "VALIDATION_FILE = '/CroppedData/validate_file.txt'\n",
    "\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "#FLAGS.image_size = 96\n",
    "flags.DEFINE_integer(\"image_size\", 96, \"image_size \")\n",
    "#FLAGS.image_color = 3\n",
    "flags.DEFINE_integer(\"image_color\", 3, \"image_color\")\n",
    "#FLAGS.maxpool_filter_size = 2\n",
    "flags.DEFINE_integer(\"maxpool_filter_size\", 2, \"maxpool_filter_size\")\n",
    "#FLAGS.num_classes=5\n",
    "flags.DEFINE_integer(\"num_classes\", 5, \"num_classes \")\n",
    "#FLAGS.batch_size=100\n",
    "flags.DEFINE_integer(\"batch_size\", 100, \"batch_size \")\n",
    "#FLAGS.learning_rate = 0.0001\n",
    "flags.DEFINE_float(\"learning_rate\", 0.0001, \"learning_rate\")\n",
    "#FLAGS.log_dir='/CroppedData/'\n",
    "flags.DEFINE_string(\"log_dir\", \"/CroppedData/\", \"log_dir\")\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')\n",
    "\n",
    "def get_input_queue(csv_file_name,num_epochs = None):\n",
    "    train_images = []\n",
    "    train_labels = []\n",
    "    for line in open(csv_file_name,'r'):\n",
    "        cols = re.split(',|\\n',line)\n",
    "        train_images.append(cols[0])\n",
    "        # 3rd column is label and needs to be converted to int type\n",
    "        train_labels.append(int(cols[2]) )\n",
    "                            \n",
    "    input_queue = tf.train.slice_input_producer([train_images,train_labels],\n",
    "                                               num_epochs = num_epochs,shuffle = True)\n",
    "    \n",
    "    return input_queue\n",
    "\n",
    "def read_data(input_queue):\n",
    "    image_file = input_queue[0]\n",
    "    label = input_queue[1]\n",
    "    \n",
    "    image =  tf.image.decode_jpeg(tf.read_file(image_file),channels=FLAGS.image_color)\n",
    "    \n",
    "    return image,label,image_file\n",
    "\n",
    "def read_data_batch(csv_file_name,batch_size=FLAGS.batch_size):\n",
    "    input_queue = get_input_queue(csv_file_name)\n",
    "    image,label,file_name= read_data(input_queue)\n",
    "    image = tf.reshape(image,[FLAGS.image_size,FLAGS.image_size,FLAGS.image_color])\n",
    "    \n",
    "    # random image\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_brightness(image,max_delta=0.5)\n",
    "    image = tf.image.random_contrast(image,lower=0.2,upper=2.0)\n",
    "    image = tf.image.random_hue(image,max_delta=0.08)\n",
    "    image = tf.image.random_saturation(image,lower=0.2,upper=2.0)\n",
    "    \n",
    "    batch_image,batch_label,batch_file = tf.train.batch([image,label,file_name],batch_size=batch_size)\n",
    "    #,enqueue_many=True)\n",
    "    batch_file = tf.reshape(batch_file,[batch_size,1])\n",
    "\n",
    "    batch_label_on_hot=tf.one_hot(tf.to_int64(batch_label),\n",
    "        FLAGS.num_classes, on_value=1.0, off_value=0.0)\n",
    "    return batch_image,batch_label_on_hot,batch_file\n",
    "\n",
    "# convolutional network layer 1\n",
    "def conv1(input_data):\n",
    "    # layer 1 (convolutional layer)\n",
    "    #FLAGS.conv1_filter_size = 3\n",
    "    #FLAGS.conv1_layer_size = 16\n",
    "    #FLAGS.stride1 = 1\n",
    "    flags.DEFINE_integer(\"conv1_filter_size\", 3, \"conv1_filter_size\")\n",
    "    flags.DEFINE_integer(\"conv1_layer_size\", 16, \"conv1_layer_size\")\n",
    "    flags.DEFINE_integer(\"stride1\", 1, \"stride1\")\n",
    "    \n",
    "    with tf.name_scope('conv_1'):\n",
    "        W_conv1 = tf.Variable(tf.truncated_normal(\n",
    "                        [FLAGS.conv1_filter_size,FLAGS.conv1_filter_size,FLAGS.image_color,FLAGS.conv1_layer_size],\n",
    "                                              stddev=0.1))\n",
    "        b1 = tf.Variable(tf.truncated_normal(\n",
    "                        [FLAGS.conv1_layer_size],stddev=0.1))\n",
    "        h_conv1 = tf.nn.conv2d(input_data,W_conv1,strides=[1,1,1,1],padding='SAME')\n",
    "        h_conv1_relu = tf.nn.relu(tf.add(h_conv1,b1))\n",
    "        h_conv1_maxpool = tf.nn.max_pool(h_conv1_relu\n",
    "                                        ,ksize=[1,2,2,1]\n",
    "                                        ,strides=[1,2,2,1],padding='SAME')\n",
    "        \n",
    "        \n",
    "    return h_conv1_maxpool\n",
    "\n",
    "# convolutional network layer 2\n",
    "def conv2(input_data):\n",
    "  #  FLAGS.conv2_filter_size = 3\n",
    "  #  FLAGS.conv2_layer_size = 32\n",
    "   # FLAGS.stride2 = 1\n",
    "    flags.DEFINE_integer(\"conv2_filter_size\", 3, \"conv1_filter_size\")\n",
    "    flags.DEFINE_integer(\"conv2_layer_size\", 32, \"conv1_layer_size\")\n",
    "    flags.DEFINE_integer(\"stride2\", 1, \"stride1\")\n",
    "    \n",
    "    with tf.name_scope('conv_2'):\n",
    "        W_conv2 = tf.Variable(tf.truncated_normal(\n",
    "                        [FLAGS.conv2_filter_size,FLAGS.conv2_filter_size,FLAGS.conv1_layer_size,FLAGS.conv2_layer_size],\n",
    "                                              stddev=0.1))\n",
    "        b2 = tf.Variable(tf.truncated_normal(\n",
    "                        [FLAGS.conv2_layer_size],stddev=0.1))\n",
    "        h_conv2 = tf.nn.conv2d(input_data,W_conv2,strides=[1,1,1,1],padding='SAME')\n",
    "        h_conv2_relu = tf.nn.relu(tf.add(h_conv2,b2))\n",
    "        h_conv2_maxpool = tf.nn.max_pool(h_conv2_relu\n",
    "                                        ,ksize=[1,2,2,1]\n",
    "                                        ,strides=[1,2,2,1],padding='SAME')\n",
    "        \n",
    "        \n",
    "    return h_conv2_maxpool\n",
    "\n",
    "# convolutional network layer 3\n",
    "def conv3(input_data):\n",
    "   # FLAGS.conv3_filter_size = 3\n",
    "   # FLAGS.conv3_layer_size = 64\n",
    "   # FLAGS.stride3 = 1\n",
    "    flags.DEFINE_integer(\"conv3_filter_size\", 3, \"conv3_filter_size\")\n",
    "    flags.DEFINE_integer(\"conv3_layer_size\", 64, \"conv3_layer_size\")\n",
    "    flags.DEFINE_integer(\"stride3\", 1, \"stride3\")\n",
    "    \n",
    "    print ('## FLAGS.stride1 ',FLAGS.stride1)\n",
    "    with tf.name_scope('conv_3'):\n",
    "        W_conv3 = tf.Variable(tf.truncated_normal(\n",
    "                        [FLAGS.conv3_filter_size,FLAGS.conv3_filter_size,FLAGS.conv2_layer_size,FLAGS.conv3_layer_size],\n",
    "                                              stddev=0.1))\n",
    "        b3 = tf.Variable(tf.truncated_normal(\n",
    "                        [FLAGS.conv3_layer_size],stddev=0.1))\n",
    "        h_conv3 = tf.nn.conv2d(input_data,W_conv3,strides=[1,1,1,1],padding='SAME')\n",
    "        h_conv3_relu = tf.nn.relu(tf.add(h_conv3,b3))\n",
    "        h_conv3_maxpool = tf.nn.max_pool(h_conv3_relu\n",
    "                                        ,ksize=[1,2,2,1]\n",
    "                                        ,strides=[1,2,2,1],padding='SAME')\n",
    "        \n",
    "        \n",
    "    return h_conv3_maxpool\n",
    "\n",
    "# convolutional network layer 3\n",
    "def conv4(input_data):\n",
    "    #FLAGS.conv4_filter_size = 5\n",
    "    #FLAGS.conv4_layer_size = 128\n",
    "    #FLAGS.stride4 = 1\n",
    "    flags.DEFINE_integer(\"conv4_filter_size\", 5, \"conv4_filter_size\")\n",
    "    flags.DEFINE_integer(\"conv4_layer_size\", 128, \"conv4_layer_size\")\n",
    "    flags.DEFINE_integer(\"stride4\", 1, \"stride4\")\n",
    "    \n",
    "    with tf.name_scope('conv_4'):\n",
    "        W_conv4 = tf.Variable(tf.truncated_normal(\n",
    "                        [FLAGS.conv4_filter_size,FLAGS.conv4_filter_size,FLAGS.conv3_layer_size,FLAGS.conv4_layer_size],\n",
    "                                              stddev=0.1))\n",
    "        b4 = tf.Variable(tf.truncated_normal(\n",
    "                        [FLAGS.conv4_layer_size],stddev=0.1))\n",
    "        h_conv4 = tf.nn.conv2d(input_data,W_conv4,strides=[1,1,1,1],padding='SAME')\n",
    "        h_conv4_relu = tf.nn.relu(tf.add(h_conv4,b4))\n",
    "        h_conv4_maxpool = tf.nn.max_pool(h_conv4_relu\n",
    "                                        ,ksize=[1,2,2,1]\n",
    "                                        ,strides=[1,2,2,1],padding='SAME')\n",
    "        \n",
    "        \n",
    "    return h_conv4_maxpool\n",
    "\n",
    "# fully connected layer 1\n",
    "def fc1(input_data):\n",
    "    input_layer_size = 6*6*FLAGS.conv4_layer_size\n",
    "   # FLAGS.fc1_layer_size = 512\n",
    "    flags.DEFINE_integer(\"fc1_layer_size\", 512, \"fc1_layer_size\")\n",
    "    \n",
    "    with tf.name_scope('fc_1'):\n",
    "        # 앞에서 입력받은 다차원 텐서를 fcc에 넣기 위해서 1차원으로 피는 작업\n",
    "        input_data_reshape = tf.reshape(input_data, [-1, input_layer_size])\n",
    "        W_fc1 = tf.Variable(tf.truncated_normal([input_layer_size,FLAGS.fc1_layer_size],stddev=0.1))\n",
    "        b_fc1 = tf.Variable(tf.truncated_normal(\n",
    "                        [FLAGS.fc1_layer_size],stddev=0.1))\n",
    "        h_fc1 = tf.add(tf.matmul(input_data_reshape,W_fc1) , b_fc1) # h_fc1 = input_data*W_fc1 + b_fc1\n",
    "        h_fc1_relu = tf.nn.relu(h_fc1)\n",
    "    \n",
    "    return h_fc1_relu\n",
    "    \n",
    "# fully connected layer 2\n",
    "def fc2(input_data):\n",
    "    #FLAGS.fc2_layer_size = 256\n",
    "    flags.DEFINE_integer(\"fc2_layer_size\", 256, \"fc2_layer_size\")\n",
    "    with tf.name_scope('fc_2'):\n",
    "        W_fc2 = tf.Variable(tf.truncated_normal([FLAGS.fc1_layer_size,FLAGS.fc2_layer_size],stddev=0.1))\n",
    "        b_fc2 = tf.Variable(tf.truncated_normal(\n",
    "                        [FLAGS.fc2_layer_size],stddev=0.1))\n",
    "        h_fc2 = tf.add(tf.matmul(input_data,W_fc2) , b_fc2) # h_fc1 = input_data*W_fc1 + b_fc1\n",
    "        h_fc2_relu = tf.nn.relu(h_fc2)\n",
    "    \n",
    "    return h_fc2_relu\n",
    "\n",
    "# final layer\n",
    "def final_out(input_data):\n",
    "\n",
    "    with tf.name_scope('final_out'):\n",
    "        W_fo = tf.Variable(tf.truncated_normal([FLAGS.fc2_layer_size,FLAGS.num_classes],stddev=0.1))\n",
    "        b_fo = tf.Variable(tf.truncated_normal(\n",
    "                        [FLAGS.num_classes],stddev=0.1))\n",
    "        h_fo = tf.add(tf.matmul(input_data,W_fo) , b_fo) # h_fc1 = input_data*W_fc1 + b_fc1\n",
    "        \n",
    "    # 최종 레이어에 softmax 함수는 적용하지 않았다. \n",
    "        \n",
    "    return h_fo\n",
    "\n",
    "# build cnn_graph\n",
    "def build_model(images,keep_prob):\n",
    "    # define CNN network graph\n",
    "    # output shape will be (*,48,48,16)\n",
    "    r_cnn1 = conv1(images) # convolutional layer 1\n",
    "    print (\"shape after cnn1 \",r_cnn1.get_shape())\n",
    "    \n",
    "    # output shape will be (*,24,24,32)\n",
    "    r_cnn2 = conv2(r_cnn1) # convolutional layer 2\n",
    "    print (\"shape after cnn2 :\",r_cnn2.get_shape() )\n",
    "    \n",
    "    # output shape will be (*,12,12,64)\n",
    "    r_cnn3 = conv3(r_cnn2) # convolutional layer 3\n",
    "    print (\"shape after cnn3 :\",r_cnn3.get_shape() )\n",
    "\n",
    "    # output shape will be (*,6,6,128)\n",
    "    r_cnn4 = conv4(r_cnn3) # convolutional layer 4\n",
    "    print (\"shape after cnn4 :\",r_cnn4.get_shape() )\n",
    "    \n",
    "    # fully connected layer 1\n",
    "    r_fc1 = fc1(r_cnn4)\n",
    "    print (\"shape after fc1 :\",r_fc1.get_shape() )\n",
    "\n",
    "    # fully connected layer2\n",
    "    r_fc2 = fc2(r_fc1)\n",
    "    print (\"shape after fc2 :\",r_fc2.get_shape() )\n",
    "    \n",
    "    ## drop out\n",
    "    # 참고 http://stackoverflow.com/questions/34597316/why-input-is-scaled-in-tf-nn-dropout-in-tensorflow\n",
    "    # 트레이닝시에는 keep_prob < 1.0 , Test 시에는 1.0으로 한다. \n",
    "    r_dropout = tf.nn.dropout(r_fc2,keep_prob)\n",
    "    print (\"shape after dropout :\",r_dropout.get_shape() ) \n",
    "    \n",
    "    # final layer\n",
    "    r_out = final_out(r_dropout)\n",
    "    print (\"shape after final layer :\",r_out.get_shape() )\n",
    "\n",
    "\n",
    "    return r_out \n",
    "\n",
    "def main(argv=None):\n",
    "    \n",
    "    # define placeholders for image data & label for traning dataset\n",
    "    \n",
    "    images = tf.placeholder(tf.float32,[None,FLAGS.image_size,FLAGS.image_size,FLAGS.image_color])\n",
    "    labels = tf.placeholder(tf.int32,[None,FLAGS.num_classes])\n",
    "    image_batch,label_batch,file_batch = read_data_batch(TRAINING_FILE) \n",
    "\n",
    "    keep_prob = tf.placeholder(tf.float32) # dropout ratio\n",
    "    prediction = build_model(images,keep_prob)\n",
    "    # define loss function\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=labels))\n",
    "\n",
    "    tf.summary.scalar('loss',loss)\n",
    "\n",
    "    #define optimizer\n",
    "    optimizer = tf.train.AdamOptimizer(FLAGS.learning_rate)\n",
    "    train = optimizer.minimize(loss)\n",
    "\n",
    "\n",
    "    # for validation\n",
    "    #with tf.name_scope(\"prediction\"):\n",
    " \n",
    "    validate_image_batch,validate_label_batch,validate_file_batch = read_data_batch(VALIDATION_FILE)\n",
    "    label_max = tf.argmax(labels,1)\n",
    "    pre_max = tf.argmax(prediction,1)\n",
    "    correct_pred = tf.equal(tf.argmax(prediction,1),tf.argmax(labels,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
    "            \n",
    "    tf.summary.scalar('accuracy',accuracy)\n",
    "        \n",
    "    \n",
    "    startTime = datetime.now()\n",
    "    \n",
    "    #build the summary tensor based on the tF collection of Summaries\n",
    "    summary = tf.summary.merge_all()\n",
    "    \n",
    "    with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)) as sess:\n",
    "        saver = tf.train.Saver() # create saver to store training model into file\n",
    "        summary_writer = tf.summary.FileWriter(FLAGS.log_dir,sess.graph)\n",
    "        \n",
    "        init_op = tf.global_variables_initializer() # use this for tensorflow 0.12rc0\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "        sess.run(init_op)\n",
    "        \n",
    "        for i in range(10000):\n",
    "            images_,labels_ = sess.run([image_batch,label_batch])\n",
    "            #sess.run(train_step,feed_dict={images:images_,labels:labels_,keep_prob:0.8})\n",
    "            sess.run(train,feed_dict={images:images_,labels:labels_,keep_prob:0.7})\n",
    "            \n",
    "            if i % 10 == 0:\n",
    "                now = datetime.now()-startTime\n",
    "                print('## time:',now,' steps:',i)         \n",
    "                \n",
    "                # print out training status\n",
    "                rt = sess.run([label_max,pre_max,loss,accuracy],feed_dict={images:images_ \n",
    "                                                          , labels:labels_\n",
    "                                                          , keep_prob:1.0})\n",
    "                print ('Prediction loss:',rt[2],' accuracy:',rt[3])\n",
    "                # validation steps\n",
    "                validate_images_,validate_labels_ = sess.run([validate_image_batch,validate_label_batch])\n",
    "                rv = sess.run([label_max,pre_max,loss,accuracy],feed_dict={images:validate_images_ \n",
    "                                                          , labels:validate_labels_\n",
    "                                                          , keep_prob:1.0})\n",
    "                print ('Validation loss:',rv[2],' accuracy:',rv[3])\n",
    "                if(rv[3] > 0.9):\n",
    "                    break\n",
    "                # validation accuracy\n",
    "                summary_str = sess.run(summary,feed_dict={images:validate_images_ \n",
    "                                                          , labels:validate_labels_\n",
    "                                                          , keep_prob:1.0})\n",
    "                summary_writer.add_summary(summary_str,i)\n",
    "                summary_writer.flush()\n",
    "        \n",
    "        saver.save(sess, '/CroppedData/face_recog3') # save session\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "        print('finish')\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
